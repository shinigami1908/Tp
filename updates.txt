# src/common/data_loader.py
import pandas as pd
from pathlib import Path
from .config import DATA_DIR, FILES, COLUMN_MAP
from .logger import get_logger

log = get_logger("data_loader")

def _read_csv_if_exists(fname):
    p = Path(DATA_DIR) / fname
    if not p.exists():
        log.warning(f"Missing file: {p}. Returning None.")
        return None
    try:
        df = pd.read_csv(p)
    except Exception as e:
        log.info(f"CSV read failed for {p}, trying Excel: {e}")
        try:
            df = pd.read_excel(p)
        except Exception as e2:
            log.error(f"Failed to read {p}: {e2}")
            return None
    # strip whitespace from headers
    df.columns = df.columns.str.strip()
    # preserve exact header spelling/case (we will look up using exact names from config)
    df.columns = [c for c in df.columns]
    # ensure employee_id is string if present
    if 'employee_id' in df.columns:
        df['employee_id'] = df['employee_id'].astype(str)
    return df

def find_column(df, candidates):
    """
    Given a DataFrame and a list of candidate column names (in priority order),
    return the first matching column name that exists in df.columns.
    Matching strategy:
      1. exact match (case-sensitive)
      2. case-insensitive match
      3. substring match (case-insensitive) - returns the first column that contains the candidate token
    Returns the matching column name (as it appears in df.columns) or None.
    """
    if df is None:
        return None
    cols = list(df.columns)

    # 1) exact match
    for c in candidates:
        if c in cols:
            return c

    # 2) case-insensitive exact
    lower_map = {col.lower(): col for col in cols}
    for c in candidates:
        lc = c.lower()
        if lc in lower_map:
            return lower_map[lc]

    # 3) substring match (candidate token in column name)
    for c in candidates:
        token = c.lower()
        for col in cols:
            if token in col.lower():
                return col

    # 4) more permissive: try token split on underscores/space pairs
    for c in candidates:
        parts = [p for p in c.replace('-', ' ').replace('.', ' ').split() if p]
        if not parts:
            continue
        for col in cols:
            cl = col.lower()
            if all(part.lower() in cl for part in parts):
                return col

    return None

def parse_dates_and_types(key, df):
    """Parse known date/month/boolean columns based on key using COLUMN_MAP and rules."""
    if df is None:
        return df
    df = df.copy()
    try:
        if key == "defects":
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], format="%m/%d/%Y", errors='coerce')
            if 'escaped_to_prod' in df.columns:
                df['escaped_to_prod'] = df['escaped_to_prod'].apply(lambda x: str(x).strip().lower() in ("1","true","yes","y","t"))
        elif key == "feedback_360":
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], format="%m/%d/%Y", errors='coerce')
            # sentiment is string (positive/constructive/mixed) â€” leave as-is
        elif key == "github_metrics":
            if 'month' in df.columns:
                # month is YYYY-MM
                df['month'] = pd.to_datetime(df['month'].astype(str) + "-01", format="%Y-%m-%d", errors='coerce')
            for c in ['commits','pull_requests','reviews_done','copilot_suggestions_accepted','copilot_suggestions_total']:
                if c in df.columns:
                    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)
        elif key == "idp_goals":
            if 'target_date' in df.columns:
                df['target_date'] = pd.to_datetime(df['target_date'], format="%m/%d/%Y", errors='coerce')
        elif key == "jira_metrics":
            for c in ['story_points_committed','story_points_completed','spillover_points','bugs_introduced','bugs_fixed']:
                if c in df.columns:
                    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
        elif key == "lms_completions":
            if 'completion_date' in df.columns:
                df['completion_date'] = pd.to_datetime(df['completion_date'], format="%m/%d/%Y", errors='coerce')
            for c in ['hours','score']:
                if c in df.columns:
                    df[c] = pd.to_numeric(df[c], errors='coerce')
        elif key == "manager_evaluations":
            # period is H1/H2 (string), rating kept as string
            if 'rating' in df.columns:
                df['rating'] = df['rating'].astype(str)
        elif key == "recognition":
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], format="%m/%d/%Y", errors='coerce')
        elif key == "release_metrics":
            if 'on_time' in df.columns:
                df['on_time'] = df['on_time'].apply(lambda x: True if str(x).strip() in ("1","True","true","YES","yes","Y","y") else False)
            if 'defect_rate_ppm' in df.columns:
                df['defect_rate_ppm'] = pd.to_numeric(df['defect_rate_ppm'], errors='coerce').fillna(0)
            if 'rollbacks' in df.columns:
                df['rollbacks'] = pd.to_numeric(df['rollbacks'], errors='coerce').fillna(0).astype(int)
        elif key == "rto":
            if 'month' in df.columns:
                df['month'] = pd.to_datetime(df['month'].astype(str) + "-01", format="%Y-%m-%d", errors='coerce')
            if 'compliant' in df.columns:
                df['compliant'] = df['compliant'].apply(lambda x: str(x).strip().lower() in ("1","true","yes","y"))
        elif key == "workday_checkins":
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], format="%m/%d/%Y", errors='coerce')
    except Exception as e:
        log.warning(f"parse_dates_and_types: problem parsing types for {key}: {e}")
    return df

def load_all():
    loaded = {}
    for key, fname in FILES.items():
        df = _read_csv_if_exists(fname)
        df = parse_dates_and_types(key, df)
        loaded[key] = df
    return loaded
