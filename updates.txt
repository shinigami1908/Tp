# src/features/feature_engineering.py
"""
Feature engineering / KPI computation.

Primary function:
  compute_kpis_from_loaded(loaded: Dict[str, pd.DataFrame]) -> (features_combined_df, features_by_period_df)

Compatibility adapter:
  compute_kpis(joined_or_loaded) -> same outputs but accepts either the old flattened `joined` DataFrame
  or the newer `loaded` dict.

Design summary:
- Aggregate per table into (employee_id, period_half) summaries (sums for numeric columns, counts for object columns).
- Merge per-table summaries together (left-merge on (employee_id, period_half)).
- Produce features_by_period (one row per employee per period) and features_combined (one row per employee).
"""
from typing import Dict, Tuple, Optional, List
import pandas as pd
from ..common.logger import get_logger

log = get_logger("feature_engineering")


def _safe_group_agg(df: pd.DataFrame,
                    group_cols: List[str],
                    numeric_aggs: Optional[List[str]] = None,
                    object_aggs: Optional[List[str]] = None) -> pd.DataFrame:
    """
    Generic helper:
      - numeric_aggs: list of numeric columns to sum
      - object_aggs: list of object columns to count non-null (or first value)
    Returns aggregated DataFrame (grouped).
    """
    if df is None or df.empty:
        # return empty df with group cols if possible
        return pd.DataFrame(columns=group_cols)

    # ensure group cols exist
    for gc in group_cols:
        if gc not in df.columns:
            # create the column with NaNs so grouping doesn't fail
            df[gc] = pd.NA

    # normalise period_half to string if present
    if "period_half" in df.columns:
        df["period_half"] = df["period_half"].astype(str)

    g = df.groupby(group_cols, dropna=False)
    agg_ops = {}

    if numeric_aggs:
        for c in numeric_aggs:
            if c in df.columns:
                agg_ops[c] = "sum"
    if object_aggs:
        for c in object_aggs:
            if c in df.columns:
                # count non-null occurrences
                agg_ops[c] = lambda s: s.notna().sum()

    # always include row count
    agg_ops["_rows"] = ("employee_id", "count")

    try:
        out = g.agg(agg_ops).reset_index()
    except Exception:
        # fallback: just return counts
        out = g.size().reset_index().rename(columns={0: "_rows"})
    return out


def compute_kpis_from_loaded(loaded: Dict[str, pd.DataFrame]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Compute KPIs using the `loaded` dict (dataframes).
    Returns:
      - features_combined_df: one row per employee (aggregated across periods)
      - features_by_period_df: one row per employee per period (period_half)
    """

    per_table_period = {}

    # defects
    df = loaded.get("defects")
    if df is not None:
        numeric = []
        object_cols = []
        # escaped_to_prod boolean -> treat as numeric (count of True)
        if "escaped_to_prod" in df.columns:
            numeric.append("escaped_to_prod")
        # severity -> count occurrences (object agg)
        if "severity" in df.columns:
            object_cols.append("severity")
        per_table_period["defects"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=numeric, object_aggs=object_cols)

    # jira_metrics
    df = loaded.get("jira_metrics")
    if df is not None:
        numeric_cols = [c for c in ["story_points_committed", "story_points_completed", "spillover_points", "bugs_introduced", "bugs_fixed"] if c in df.columns]
        per_table_period["jira"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=numeric_cols, object_aggs=None)

    # github_metrics
    df = loaded.get("github_metrics")
    if df is not None:
        numeric_cols = [c for c in ["commits", "pull_requests", "reviews_done", "copilot_suggestions_accepted", "copilot_suggestions_total"] if c in df.columns]
        per_table_period["github"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=numeric_cols, object_aggs=None)

    # feedback_360
    df = loaded.get("feedback_360")
    if df is not None:
        # sentiment counts (positive/constructive/mixed) are captured as counts via object agg
        obj_cols = ["sentiment"] if "sentiment" in df.columns else None
        per_table_period["feedback"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=None, object_aggs=obj_cols)

    # rto
    df = loaded.get("rto")
    if df is not None:
        numeric_cols = [c for c in ["required_days", "in_office_days"] if c in df.columns]
        if "compliant" in df.columns:
            numeric_cols.append("compliant")
        per_table_period["rto"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=numeric_cols, object_aggs=None)

    # lms_completions
    df = loaded.get("lms_completions")
    if df is not None:
        numeric_cols = [c for c in ["hours", "score"] if c in df.columns]
        per_table_period["lms"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=numeric_cols, object_aggs=None)

    # recognition
    df = loaded.get("recognition")
    if df is not None:
        per_table_period["recognition"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=None, object_aggs=["type"] if "type" in df.columns else None)

    # idp_goals
    df = loaded.get("idp_goals")
    if df is not None:
        obj_cols = ["status"] if "status" in df.columns else None
        per_table_period["idp"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=None, object_aggs=obj_cols)

    # manager_evaluations
    df = loaded.get("manager_evaluations")
    if df is not None:
        obj_cols = []
        if "rating" in df.columns:
            obj_cols.append("rating")
        if "bias_type" in df.columns:
            obj_cols.append("bias_type")
        per_table_period["mgr_eval"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=None, object_aggs=obj_cols)

    # workday_checkins
    df = loaded.get("workday_checkins")
    if df is not None:
        obj_cols = ["sentiment"] if "sentiment" in df.columns else None
        per_table_period["checkins"] = _safe_group_agg(df, ["employee_id", "period_half"], numeric_aggs=None, object_aggs=obj_cols)

    # Build the canonical set of (employee_id, period_half) keys
    all_keys = []
    for name, agg_df in per_table_period.items():
        if agg_df is None or agg_df.empty:
            continue
        if {"employee_id", "period_half"}.issubset(agg_df.columns):
            all_keys.append(agg_df[["employee_id", "period_half"]].drop_duplicates())

    if all_keys:
        keys_df = pd.concat(all_keys, ignore_index=True).drop_duplicates().reset_index(drop=True)
    else:
        # fallback to employees table
        emp_df = loaded.get("employees")
        if emp_df is not None and "employee_id" in emp_df.columns:
            keys_df = emp_df[["employee_id"]].drop_duplicates().assign(period_half="unknown")
        else:
            keys_df = pd.DataFrame(columns=["employee_id", "period_half"])

    merged = keys_df.copy()

    # sequentially merge in prefixed aggregated tables
    for name, agg_df in per_table_period.items():
        if agg_df is None or agg_df.empty:
            continue
        pref = f"{name}__"
        # rename all non-key cols
        agg_copy = agg_df.copy()
        for c in agg_copy.columns:
            if c not in ("employee_id", "period_half"):
                agg_copy = agg_copy.rename(columns={c: pref + c})
        merged = merged.merge(agg_copy, on=["employee_id", "period_half"], how="left")

    # Fill NAs with 0 for numeric-like columns
    for c in merged.columns:
        if c in ("employee_id", "period_half"):
            continue
        try:
            merged[c] = pd.to_numeric(merged[c], errors="coerce").fillna(0)
        except Exception:
            # if cannot coerce, fill NaNs with 0 anyway to keep consistency
            merged[c] = merged[c].fillna(0)

    features_by_period_df = merged

    # features_combined: aggregate across periods per employee (sum numeric columns)
    if not features_by_period_df.empty:
        numeric_cols = [c for c in features_by_period_df.columns if c not in ("employee_id", "period_half")]
        features_combined_df = features_by_period_df.groupby("employee_id", dropna=False)[numeric_cols].sum().reset_index()
    else:
        features_combined_df = pd.DataFrame(columns=["employee_id"])

    log.info("Feature engineering produced: features_by_period rows=%s, features_combined rows=%s",
             len(features_by_period_df), len(features_combined_df))

    return features_combined_df, features_by_period_df


def compute_kpis(joined_or_loaded) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Compatibility adapter.

    If passed a dict (the `loaded` dict), call compute_kpis_from_loaded.
    If passed a DataFrame (the old 'joined' flattened table), aggregate per-employee and per-period (best-effort).
    Returns (features_combined_df, features_by_period_df)
    """
    # If it's a dict, assume the loaded dict
    if isinstance(joined_or_loaded, dict):
        return compute_kpis_from_loaded(joined_or_loaded)

    # If it's a DataFrame, attempt to derive period-based aggregates
    if isinstance(joined_or_loaded, pd.DataFrame):
        joined = joined_or_loaded.copy()
        # ensure expected columns exist
        if "employee_id" not in joined.columns:
            raise ValueError("Joined dataframe must contain 'employee_id' column")
        # ensure period_half exists (if not, try to use 'period' or set unknown)
        if "period_half" not in joined.columns:
            if "period" in joined.columns:
                joined["period_half"] = joined["period"].astype(str)
            else:
                joined["period_half"] = "unknown"

        # For a flattened joined df we will sum numeric columns per employee+period and count rows
        # pick numeric columns automatically (exclude obvious non-metric columns)
        metric_cols = [c for c in joined.columns if c not in ("employee_id", "period_half", "period", "name", "emp_role", "role")]
        # coerce numeric where possible
        numeric_cols = []
        for c in metric_cols:
            try:
                joined[c] = pd.to_numeric(joined[c], errors="coerce")
                numeric_cols.append(c)
            except Exception:
                # non-numeric columns will be counted instead
                pass

        g = joined.groupby(["employee_id", "period_half"], dropna=False)
        if numeric_cols:
            agg = g[numeric_cols].sum().reset_index()
        else:
            agg = g.size().reset_index().rename(columns={0: "_rows"})

        features_by_period_df = agg
        # combined
        if not features_by_period_df.empty:
            numeric_cols = [c for c in features_by_period_df.columns if c not in ("employee_id", "period_half")]
            features_combined_df = features_by_period_df.groupby("employee_id", dropna=False)[numeric_cols].sum().reset_index()
        else:
            features_combined_df = pd.DataFrame(columns=["employee_id"])
        return features_combined_df, features_by_period_df

    raise ValueError("Unsupported input to compute_kpis: must be either loaded dict or joined DataFrame")
