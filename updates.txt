# src/llm/generator.py

"""
LLM orchestration WITHOUT Tachyon file upload.

We directly provide HR report card data for the manager's employees to the GPT prompt.
"""

from pathlib import Path
import json
import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional

from src.common.logger import get_logger
from .llm_generation import TachyonChatManager
from .prompts import MANAGER_INSIGHTS_SYSTEM_PROMPT, MANAGER_INSIGHTS_USER_FULLDATA_TEMPLATE

log = get_logger("generator")


def get_current_manager_id() -> str:
    """Temporary default manager until frontend login is integrated."""
    return "M100"


def _json_safe(val: Any) -> Any:
    if isinstance(val, (np.generic,)):
        val = val.item()
    try:
        if isinstance(val, (float, int, str)) and pd.isna(val):
            return None
    except Exception:
        pass
    return val


def _load_frames() -> Optional[tuple]:
    base_dir = Path(".")

    md = base_dir / "mockdata" / "employees.csv"
    bp = base_dir / "output" / "features_by_period.json"
    cb = base_dir / "output" / "features_combined.json"

    if not (md.exists() and bp.exists() and cb.exists()):
        log.error("Missing one or more required ETL output files.")
        return None

    employees_df = pd.read_csv(md)
    by_period_df = pd.read_json(bp)
    combined_df = pd.read_json(cb)

    for df in [employees_df, by_period_df, combined_df]:
        df.columns = df.columns.str.strip()

    return employees_df, by_period_df, combined_df


def build_manager_reports(manager_id: str) -> List[Dict[str, Any]]:
    frames = _load_frames()
    if frames is None:
        return []

    employees_df, by_period_df, combined_df = frames

    team = employees_df[employees_df["manager_id"] == manager_id]
    if team.empty:
        log.warning("No employees for manager %s", manager_id)
        return []

    reports = []

    for _, emp in team.iterrows():
        emp_id = emp["employee_id"]

        periods = by_period_df[by_period_df["employee_id"] == emp_id]
        combined = combined_df[combined_df["employee_id"] == emp_id]

        # JSON safe conversion
        period_rows = [
            {c: _json_safe(r[c]) for c in r.index if c != "employee_id"}
            for _, r in periods.iterrows()
        ]

        combined_dict = (
            {c: _json_safe(combined.iloc[0][c]) for c in combined.columns if c != "employee_id"}
            if not combined.empty else {}
        )

        reports.append(
            {
                "employee_id": emp_id,
                "name": emp.get("name"),
                "role": emp.get("role"),
                "org": emp.get("org"),
                "periods": period_rows,
                "combined_extra": combined_dict,
            }
        )

    return reports


def _strip_code_fences(raw: str) -> str:
    txt = raw.strip()
    if txt.startswith("```"):
        txt = txt[3:].lstrip()
        if txt.lower().startswith("json"):
            txt = txt[4:].lstrip()
        end = txt.rfind("```")
        if end != -1:
            txt = txt[:end].strip()
    return txt


def generate_manager_gpt_insights(manager_id: Optional[str] = None) -> Any:
    if manager_id is None:
        manager_id = get_current_manager_id()

    log.info("Preparing GPT insights for manager %s", manager_id)

    reports = build_manager_reports(manager_id)
    if not reports:
        return {"status": "error", "detail": "No employees for manager."}

    # GPT Payload
    reports_json = json.dumps(reports, indent=2)

    tcm = TachyonChatManager()

    user_prompt = MANAGER_INSIGHTS_USER_FULLDATA_TEMPLATE.format(
        manager_id=manager_id,
        report_data=reports_json,
    )

    messages = [
        {"role": "system", "content": MANAGER_INSIGHTS_SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt},
    ]

    resp = tcm.chat_complete(messages=messages)

    try:
        content = resp.choices[0].message.content
    except Exception:
        return {"status": "error", "detail": "Bad GPT response"}

    cleaned = _strip_code_fences(content)
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)

    output_path = output_dir / f"manager_{manager_id}_insights.json"
    raw_path = output_dir / f"manager_{manager_id}_insights_raw.txt"

    try:
        parsed = json.loads(cleaned)
        json.dump(parsed, open(output_path, "w"), indent=2)
        return parsed
    except Exception:
        open(raw_path, "w").write(content)
        return {"status": "raw_only", "detail": "JSON parse failed"}


if __name__ == "__main__":
    generate_manager_gpt_insights()
